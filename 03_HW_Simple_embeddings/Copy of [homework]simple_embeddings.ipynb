{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of [homework]simple_embeddings.ipynb","provenance":[{"file_id":"1BztsE3lpr33tjPKzTGswuDMUGB4KQ5fY","timestamp":1613497174335}],"collapsed_sections":["0sUSxk866j1_"]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.1"},"widgets":{"application/vnd.jupyter.widget-state+json":{"9851defd92314769aad608d6af90f5cf":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2444be56eec946cd855f4576a9264af5","IPY_MODEL_1655a6c1272645f7b94504971249a8f8"],"layout":"IPY_MODEL_7012f0d3a4c3423c99818628a392e374"}},"7012f0d3a4c3423c99818628a392e374":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2444be56eec946cd855f4576a9264af5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":" 27%","description_tooltip":null,"layout":"IPY_MODEL_0a9adfbe630f4b24a6c92eb2dbbedf2e","max":3760,"min":0,"orientation":"horizontal","style":"IPY_MODEL_560816be734345a79eb5b5c33ab799d3","value":1000}},"1655a6c1272645f7b94504971249a8f8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4a750dee054345a6a46b965187ecc8da","placeholder":"​","style":"IPY_MODEL_5761c518aae04e46b31903d49e9d773b","value":" 1000/3760 [01:40&lt;03:44, 12.30it/s]"}},"560816be734345a79eb5b5c33ab799d3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}},"0a9adfbe630f4b24a6c92eb2dbbedf2e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5761c518aae04e46b31903d49e9d773b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4a750dee054345a6a46b965187ecc8da":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"618445bfdbaf42df80fdf41f5da07987":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5d5b691a31bd470780f4c1cace1d855a","IPY_MODEL_86f525398c774ee6a870cf232b81bbff"],"layout":"IPY_MODEL_9d26a4b8d7a94d2b9a463f27b0cf656b"}},"9d26a4b8d7a94d2b9a463f27b0cf656b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5d5b691a31bd470780f4c1cace1d855a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"100%","description_tooltip":null,"layout":"IPY_MODEL_93208314c312407fa0a0e0492726b725","max":6,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b5272cdc883143c3a83eb48eb5d43af5","value":6}},"86f525398c774ee6a870cf232b81bbff":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b8a99cb7513b449ba972b3a0b3c46d67","placeholder":"​","style":"IPY_MODEL_fa6ad6aea8ec48c1aa21863c56c9e6dd","value":" 6/6 [00:00&lt;00:00, 29.72it/s]"}},"b5272cdc883143c3a83eb48eb5d43af5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}},"93208314c312407fa0a0e0492726b725":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fa6ad6aea8ec48c1aa21863c56c9e6dd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b8a99cb7513b449ba972b3a0b3c46d67":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f8d6d55d897d4570b291540b11468ef8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c67e50b277124fc59519073d17c3e51a","IPY_MODEL_59e94b410ba84b60a42fc9a36f8e6410"],"layout":"IPY_MODEL_92dcbbb6ac59491191ce238ea767a270"}},"92dcbbb6ac59491191ce238ea767a270":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c67e50b277124fc59519073d17c3e51a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":" 27%","description_tooltip":null,"layout":"IPY_MODEL_f6383d73994e44478df1eacea5495ace","max":3760,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e2fe3448bab243be99074f86bf0f241c","value":999}},"59e94b410ba84b60a42fc9a36f8e6410":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c4e01c9905c947e4bae347c4016bc8af","placeholder":"​","style":"IPY_MODEL_5b1ed1eb547b4122a1a09a759858a4d8","value":" 999/3760 [01:55&lt;04:40,  9.85it/s]"}},"e2fe3448bab243be99074f86bf0f241c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}},"f6383d73994e44478df1eacea5495ace":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5b1ed1eb547b4122a1a09a759858a4d8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c4e01c9905c947e4bae347c4016bc8af":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a634d8905b61472d9a49ec98a8dd3c69":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_35f7683d90d840978829ddde572e0aff","IPY_MODEL_dc4c6a7200c44d608f6219eab4270e60"],"layout":"IPY_MODEL_94edfbe393044f7d9a4a9eb2770098d1"}},"94edfbe393044f7d9a4a9eb2770098d1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"35f7683d90d840978829ddde572e0aff":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"100%","description_tooltip":null,"layout":"IPY_MODEL_fe79bcadd97e40129488d13a2117ac16","max":6,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0f6756231d0d4eb7bf7956c8d48a098c","value":6}},"dc4c6a7200c44d608f6219eab4270e60":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bc1ddf427a4d4b0ab1502911e5915085","placeholder":"​","style":"IPY_MODEL_526f58fe6d734e778d1c7b3128b11761","value":" 6/6 [00:00&lt;00:00, 10.04it/s]"}},"0f6756231d0d4eb7bf7956c8d48a098c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}},"fe79bcadd97e40129488d13a2117ac16":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"526f58fe6d734e778d1c7b3128b11761":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bc1ddf427a4d4b0ab1502911e5915085":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"yX986zrQeEHH"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1BYoacT8eLTs","executionInfo":{"elapsed":792,"status":"ok","timestamp":1614270605623,"user":{"displayName":"George Batchkala","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjDONxhSnrmdSTlEhvc2cJI7El4zBMhqZjcA1cl1A=s64","userId":"05060257197849650568"},"user_tz":0},"outputId":"1a9842a3-0214-48f2-e2dd-6794f7146082"},"source":["%cd drive/MyDrive/colab_projects/nlp_from_dls/3_HW_Simple_embeddings/"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/colab_projects/nlp_from_dls/3_HW_Simple_embeddings\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9i1wYKkhDtnu","executionInfo":{"elapsed":1262,"status":"ok","timestamp":1614270606439,"user":{"displayName":"George Batchkala","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjDONxhSnrmdSTlEhvc2cJI7El4zBMhqZjcA1cl1A=s64","userId":"05060257197849650568"},"user_tz":0},"outputId":"c1b313d3-361b-4831-cd95-0211e21f0f66"},"source":["%ls"],"execution_count":null,"outputs":[{"output_type":"stream","text":["'Copy of [homework]simple_embeddings.ipynb'\n"," \u001b[0m\u001b[01;34mdata\u001b[0m/\n","'SO_vectors_200.bin?download=1'\n"," stackoverflow_similar_questions.zip\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Ot3c4fjZwC4T"},"source":["<img src=\"https://s8.hostingkartinok.com/uploads/images/2018/08/308b49fcfbc619d629fe4604bceb67ac.jpg\" width=500, height=450>\n","<h3 style=\"text-align: center;\"><b>Физтех-Школа Прикладной математики и информатики (ФПМИ) МФТИ</b></h3>"]},{"cell_type":"markdown","metadata":{"id":"P2JdzEXmwRU5"},"source":["---"]},{"cell_type":"markdown","metadata":{"id":"Fc8iHXIVwDwj"},"source":["***Some parts of the notebook are almost the copy of [ mmta-team course](https://github.com/mmta-team/mmta_fall_2020). Special thanks to mmta-team for making them publicly available. [Original notebook](https://github.com/mmta-team/mmta_fall_2020/blob/master/tasks/01_word_embeddings/task_word_embeddings.ipynb).***"]},{"cell_type":"markdown","metadata":{"id":"7D0wm5jt6j0U"},"source":["<b> Прочитайте семинар, пожалуйста, для успешного выполнения домашнего задания. В конце ноутка напишите свой вывод. Работа без вывода оценивается ниже."]},{"cell_type":"markdown","metadata":{"id":"BIWqBuEa6j0b"},"source":["## Задача поиска схожих по смыслу предложений"]},{"cell_type":"markdown","metadata":{"id":"NUkwMPLA6j0g"},"source":["Мы будем ранжировать вопросы [StackOverflow](https://stackoverflow.com) на основе семантического векторного представления "]},{"cell_type":"markdown","metadata":{"id":"dNRXIEfu5a3Q"},"source":["До этого в курсе не было речи про задачу ранжировния, поэтому введем математическую формулировку"]},{"cell_type":"markdown","metadata":{"id":"uS9FwWNd5a3S"},"source":["## Задача ранжирования(Learning to Rank)"]},{"cell_type":"markdown","metadata":{"id":"wdwY9-f75a3T"},"source":["* $X$ - множество объектов\n","* $X^l = \\{x_1, x_2, ..., x_l\\}$ - обучающая выборка\n","<br>На обучающей выборке задан порядок между некоторыми элементами, то есть нам известно, что некий объект выборки более релевантный для нас, чем другой:\n","* $i \\prec j$ - порядок пары индексов объектов на выборке $X^l$ c индексами $i$ и $j$\n","### Задача:\n","построить ранжирующую функцию $a$ : $X \\rightarrow R$ такую, что\n","$$i \\prec j \\Rightarrow a(x_i) < a(x_j)$$"]},{"cell_type":"markdown","metadata":{"id":"WG2IGBsh5a3U"},"source":["<img src=\"https://d25skit2l41vkl.cloudfront.net/wp-content/uploads/2016/12/Featured-Image.jpg\" width=500, height=450>"]},{"cell_type":"markdown","metadata":{"id":"MQk_rolFwT_h"},"source":["### Embeddings"]},{"cell_type":"markdown","metadata":{"id":"xUe1PGXn6j0l"},"source":["Будем использовать предобученные векторные представления слов на постах Stack Overflow.<br>\n","[A word2vec model trained on Stack Overflow posts](https://github.com/vefstathiou/SO_word2vec)"]},{"cell_type":"code","metadata":{"id":"mYkI54Y-rk7a"},"source":["# try next cell one first, maybe it's already loaded\n","#\n","# !wget https://zenodo.org/record/1199620/files/SO_vectors_200.bin?download=1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O8YJTOYv6j0s","executionInfo":{"elapsed":39043,"status":"ok","timestamp":1614270648448,"user":{"displayName":"George Batchkala","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjDONxhSnrmdSTlEhvc2cJI7El4zBMhqZjcA1cl1A=s64","userId":"05060257197849650568"},"user_tz":0},"outputId":"a8db9231-c563-4f49-8344-5c6050553ed7"},"source":["%%time\n","\n","from gensim.models.keyedvectors import KeyedVectors\n","wv_embeddings = KeyedVectors.load_word2vec_format(\"SO_vectors_200.bin?download=1\", binary=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["CPU times: user 30.1 s, sys: 4.42 s, total: 34.5 s\n","Wall time: 37.8 s\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"8QLUHw9U9HG9"},"source":["Больше инфы про [KeyedVectors](https://radimrehurek.com/gensim/models/keyedvectors.html) в документации [gensim](https://radimrehurek.com/gensim/auto_examples/index.html#documentation).\n","\n"]},{"cell_type":"markdown","metadata":{"id":"aIcT_g-C6j1E"},"source":["#### Как пользоваться этими векторами?"]},{"cell_type":"markdown","metadata":{"id":"DWO5SPDY6j1G"},"source":["Посмотрим на примере одного слова, что из себя представляет embedding"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KeSBlQfk6j1J","scrolled":true,"executionInfo":{"elapsed":38718,"status":"ok","timestamp":1614270648449,"user":{"displayName":"George Batchkala","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjDONxhSnrmdSTlEhvc2cJI7El4zBMhqZjcA1cl1A=s64","userId":"05060257197849650568"},"user_tz":0},"outputId":"449707a4-f4c5-48d3-a2ab-fa97bb02c73a"},"source":["word = 'dog'\n","if word in wv_embeddings:\n","    print(wv_embeddings[word].dtype, wv_embeddings[word].shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["float32 (200,)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LuXcsWupHTVy","executionInfo":{"elapsed":38634,"status":"ok","timestamp":1614270648449,"user":{"displayName":"George Batchkala","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjDONxhSnrmdSTlEhvc2cJI7El4zBMhqZjcA1cl1A=s64","userId":"05060257197849650568"},"user_tz":0},"outputId":"4a2cf5a6-0681-43ff-a1e3-ecf2b4f38bdf"},"source":["# have a look at the first 20 values\n","print(wv_embeddings['dog'][:20])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[ 0.6851772  -1.2778991  -0.41913974  1.3623164  -3.1675398   0.09950767\n","  0.6402681  -1.1245339  -0.6699619  -0.6998852   0.4936771  -0.40500194\n"," -3.0706816  -2.2809966   0.85798043  2.7093108   0.3492745  -0.03494101\n"," -0.22330493  1.2290467 ]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T4Eq-D1qxpMJ","executionInfo":{"elapsed":38552,"status":"ok","timestamp":1614270648449,"user":{"displayName":"George Batchkala","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjDONxhSnrmdSTlEhvc2cJI7El4zBMhqZjcA1cl1A=s64","userId":"05060257197849650568"},"user_tz":0},"outputId":"4c72068d-c5d8-4228-a923-21b1e06d6918"},"source":["print(type(wv_embeddings.index2word))\n","print(f\"Num of words: {len(wv_embeddings.index2word)}\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["<class 'list'>\n","Num of words: 1787145\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YfgaSXewcVPa","executionInfo":{"elapsed":38468,"status":"ok","timestamp":1614270648449,"user":{"displayName":"George Batchkala","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjDONxhSnrmdSTlEhvc2cJI7El4zBMhqZjcA1cl1A=s64","userId":"05060257197849650568"},"user_tz":0},"outputId":"9b534be6-ddca-41a3-f6e9-89832fa933ed"},"source":["# examples of words\n","print('Words', 5*' ', 'First 10 (out of 200) values in the embedding')\n","print('-'*83)\n","\n","for i, word in enumerate(wv_embeddings.index2word):\n","    if i < 20:\n","        print(word, (10-len(word)) * ' ', wv_embeddings[word][:10].round(3))\n","    else:\n","        break"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Words       First 10 (out of 200) values in the embedding\n","-----------------------------------------------------------------------------------\n","use         [-1.325  2.425 -0.49   2.941 -3.2    1.971  2.733  0.68  -0.77  -2.533]\n","code        [ 0.774 -0.671  0.139  3.103  0.163  2.15   0.1   -1.269 -0.649 -1.672]\n","using       [-0.295  1.666 -1.025  2.713 -2.156 -0.339  1.496  0.294  1.283 -2.021]\n","like        [-0.691 -0.583 -1.066  1.855 -0.94  -0.032  3.284 -0.216 -0.161 -1.501]\n","will        [ 0.24  -2.395  0.88   4.439 -1.777  1.392  2.478  1.205 -1.943 -0.935]\n","want        [ 1.849  0.291  0.309  3.915 -2.856  1.17   2.392  1.68  -0.559 -0.628]\n","need        [ 0.49   0.097  0.357  2.639 -2.237  0.56   1.019  0.883 -0.407 -0.15 ]\n","get         [-0.021 -1.979 -1.851  2.119  0.541  0.213  0.519  2.215  0.031 -2.57 ]\n","file        [ 1.465  2.534 -2.501  3.009 -0.668  3.837  1.379  0.758 -0.158  1.483]\n","one         [-0.81   1.657 -1.19   1.862 -1.146  0.499  1.678 -0.369 -0.545 -0.86 ]\n","just        [ 2.134  1.085 -1.11   3.188 -1.374  2.626  1.78   0.41  -0.466  0.555]\n","data        [ 1.425 -1.064 -0.706  1.613 -0.889 -0.63   4.683 -1.196  4.399  1.668]\n","way         [ 1.054 -2.078 -1.43   3.178 -0.94   1.062 -2.431 -2.523 -1.277 -0.068]\n","1           [-0.542 -0.521 -0.074  1.412 -2.037 -1.142  1.306  3.448 -2.014 -2.406]\n","also        [-1.426  2.191  0.431  2.469 -0.957  0.526  0.625 -0.401  1.009 -0.544]\n","function    [ 0.583 -2.134 -2.125  3.47   1.439  3.075 -0.341  2.357  0.055  0.927]\n","problem     [ 2.294  0.649 -0.362 -2.709  0.688  0.808 -1.844 -1.285 -2.844  2.148]\n","error       [ 3.158 -0.255  1.627  1.192  2.53   1.408  1.327 -3.15  -1.028  2.756]\n","-           [-0.739  0.289  0.049  0.86  -0.924  2.308  0.78   1.486 -0.035 -0.919]\n","example     [ 0.523  1.15   0.059  3.021 -1.175  1.597  0.963  0.276  0.449 -3.387]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6sB1KAWLcfr-","executionInfo":{"elapsed":38386,"status":"ok","timestamp":1614270648450,"user":{"displayName":"George Batchkala","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjDONxhSnrmdSTlEhvc2cJI7El4zBMhqZjcA1cl1A=s64","userId":"05060257197849650568"},"user_tz":0},"outputId":"266a85bf-0b7a-4491-fc9d-af145d67da7a"},"source":["type(wv_embeddings.vocab), len(wv_embeddings.vocab)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(dict, 1787145)"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b-QtqeKxdyB0","executionInfo":{"elapsed":38296,"status":"ok","timestamp":1614270648450,"user":{"displayName":"George Batchkala","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjDONxhSnrmdSTlEhvc2cJI7El4zBMhqZjcA1cl1A=s64","userId":"05060257197849650568"},"user_tz":0},"outputId":"10e2ee58-cea3-4839-8387-e1ae1894eecc"},"source":["wv_embeddings.vocab['job']"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<gensim.models.keyedvectors.Vocab at 0x7fd5f431a810>"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"markdown","metadata":{"id":"ZT6NTCys6j1Q"},"source":["Найдем наиболее близкие слова к слову `dog`:"]},{"cell_type":"markdown","metadata":{"id":"n08z2PjMwC5o"},"source":["#### Вопрос 1:\n","* Входит ли слов `cat` топ-5 близких слов к слову `dog`? Какое место? "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nYwVz0xG6j1U","scrolled":true,"executionInfo":{"elapsed":41692,"status":"ok","timestamp":1614270652097,"user":{"displayName":"George Batchkala","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjDONxhSnrmdSTlEhvc2cJI7El4zBMhqZjcA1cl1A=s64","userId":"05060257197849650568"},"user_tz":0},"outputId":"b0272f11-5052-43c7-f383-463afa71e938"},"source":["# method most_simmilar\n","\n","\n","# idea from: https://github.com/vefstathiou/SO_word2vec\n","try:\n","    result = wv_embeddings.most_similar('dog', topn=5)\n","except KeyError as e:\n","        print(e)\n","\n","\n","# print numbers and words, not really interested in similarities\n","for i, (sim_word, similarity) in enumerate(result):\n","    print(i, sim_word, (10-len(sim_word))*' ', similarity)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0 animal      0.8564180135726929\n","1 dogs        0.7880867123603821\n","2 mammal      0.7623804807662964\n","3 cats        0.7621253728866577\n","4 animals     0.760793924331665\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"tq7KjX9ZABpi"},"source":["`cat`не входит. Но `cats` на 4 месте (считая с 1).\n","\n","Странно, что \"dogs\" дальше от 'dog', чем 'animal'. Число, видимо, играет роль."]},{"cell_type":"markdown","metadata":{"id":"ai48-5vv6j1d"},"source":["### Векторные представления текста\n","\n","Перейдем от векторных представлений отдельных слов к векторным представлениям вопросов, как к **среднему** векторов всех слов в вопросе. Если для какого-то слова нет предобученного вектора, то его нужно пропустить. Если вопрос не содержит ни одного известного слова, то нужно вернуть нулевой вектор."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NhSnCYUcgriH","executionInfo":{"elapsed":42355,"status":"ok","timestamp":1614270653006,"user":{"displayName":"George Batchkala","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjDONxhSnrmdSTlEhvc2cJI7El4zBMhqZjcA1cl1A=s64","userId":"05060257197849650568"},"user_tz":0},"outputId":"452f859d-469d-4259-8adf-65e61db9aa21"},"source":["import nltk\n","nltk.download('stopwords')\n","from nltk.corpus import stopwords\n","\n","stopWords = set(stopwords.words('english'))\n","print(stopWords)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","{'do', 'between', \"you'd\", 'having', 'hasn', \"you're\", 'and', \"weren't\", 'wouldn', 'so', 'very', 've', 'why', 'its', 'few', 'than', \"that'll\", 'off', 'don', 'these', 'hers', 'on', \"you've\", 'what', \"wouldn't\", 'then', 'theirs', 'had', 's', 'too', 'him', 'our', 'haven', \"needn't\", \"doesn't\", 'was', 'under', 'in', 'didn', 'myself', 'are', \"wasn't\", 'until', \"don't\", 'themselves', 'further', 'other', 'as', 'the', 'while', 'that', 'below', 'most', \"haven't\", \"hasn't\", 'or', \"hadn't\", 'd', 'each', 're', 'they', \"shan't\", 'but', 't', 'm', \"isn't\", 'if', 'there', 'his', 'about', 'were', 'doesn', 'with', 'to', 'am', 'ours', 'has', 'up', 'those', 'be', 'my', 'this', 'who', 'her', 'before', 'i', 'during', 'for', 'll', 'should', 'out', 'mustn', 'some', 'y', 'down', 'nor', 'over', 'just', 'more', 'whom', 'here', \"it's\", 'their', 'when', 'she', 'above', 'herself', 'through', 'ma', 'again', \"she's\", 'itself', 'from', 'now', 'me', 'won', 'yourself', 'because', 'needn', 'aren', 'is', 'will', 'you', 'once', 'does', 'own', \"shouldn't\", 'shouldn', 'an', 'yourselves', 'no', 'ain', 'a', 'into', 'same', \"aren't\", \"won't\", 'doing', 'hadn', 'of', 'all', 'can', 'how', 'been', 'your', 'after', 'shan', 'being', 'it', 'against', 'any', 'did', 'o', \"mustn't\", \"mightn't\", 'he', 'which', 'not', 'them', 'we', 'mightn', 'ourselves', \"couldn't\", 'only', \"you'll\", 'by', 'such', 'couldn', 'himself', 'isn', 'both', 'wasn', \"should've\", \"didn't\", 'yours', 'weren', 'where', 'at', 'have'}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sEhp-liEYppJ"},"source":["import spacy\n","nlp = spacy.load('en')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EhNuxBJd6j1f","executionInfo":{"elapsed":44041,"status":"ok","timestamp":1614270654862,"user":{"displayName":"George Batchkala","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjDONxhSnrmdSTlEhvc2cJI7El4zBMhqZjcA1cl1A=s64","userId":"05060257197849650568"},"user_tz":0},"outputId":"924b034a-c862-4862-a145-0413e842a4d2"},"source":["import numpy as np\n","import re\n","# you can use your tokenizer\n","# for example, from nltk.tokenize import WordPunctTokenizer\n","class MyTokenizer:\n","    def __init__(self):\n","        pass\n","    def tokenize(self, text):\n","        # modifications\n","        #   Do not split +# from words\n","        #   use .lower()\n","        tokens = re.findall('\\w+[+#]*', text.lower())\n","        tokens = [t for t in tokens if t not in stopWords]\n","\n","        return tokens\n","\n","\n","my_tokenizer = MyTokenizer()\n","print(my_tokenizer.tokenize(\"Tolstoy began writing War and Peace in 1863, the year that he finally married and settled down at his country estate. He wrote it in c++ instead of c#.\"), '\\n')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["['tolstoy', 'began', 'writing', 'war', 'peace', '1863', 'year', 'finally', 'married', 'settled', 'country', 'estate', 'wrote', 'c++', 'instead', 'c#'] \n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Db_9qoOnOFmq"},"source":["Our custom tokenizer **takes out** the spaces and punctuation and **uses them as separators**."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2IX6pAQ3OYOj","executionInfo":{"elapsed":43874,"status":"ok","timestamp":1614270654863,"user":{"displayName":"George Batchkala","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjDONxhSnrmdSTlEhvc2cJI7El4zBMhqZjcA1cl1A=s64","userId":"05060257197849650568"},"user_tz":0},"outputId":"f9db88a6-bcb9-4851-be24-f319b0c58424"},"source":["from nltk.tokenize import WordPunctTokenizer\n","\n","nltk_tokenizer = WordPunctTokenizer()\n","print(nltk_tokenizer.tokenize(\"Tolstoy began writing War and Peace in 1863, the year that he finally married and settled down at his country estate. He wrote it in c++ instead of c#.\"), '\\n')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["['Tolstoy', 'began', 'writing', 'War', 'and', 'Peace', 'in', '1863', ',', 'the', 'year', 'that', 'he', 'finally', 'married', 'and', 'settled', 'down', 'at', 'his', 'country', 'estate', '.', 'He', 'wrote', 'it', 'in', 'c', '++', 'instead', 'of', 'c', '#.'] \n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"vpXnCoR9PBIT"},"source":["The `WordPunctTokenizer` does not take out the punctuation. Might be useful for getting to know where the sentences split, but it splits the symbols from languages, e.g. C++, and C# will be stripped from the symbols."]},{"cell_type":"code","metadata":{"id":"YHcvu6186j1m"},"source":["def question_to_vec(question, embeddings, tokenizer, dim=200):\n","    \"\"\"\n","        question: строка\n","        embeddings: наше векторное представление\n","        dim: размер любого вектора в нашем представлении\n","        \n","        return: векторное представление для вопроса\n","    \"\"\"\n","    tokens = tokenizer.tokenize(question)\n","    res = np.zeros(dim)\n","\n","    known_tokens = 0\n","    for token in tokens:\n","        \n","        if token in embeddings:\n","            assert(len(embeddings[token]) == dim)\n","            res += embeddings[token]\n","            known_tokens += 1\n","    \n","    # none of the tokens are in the embeddings\n","    #   => res stayed as it was initialized (np.zeros(dim))\n","    if known_tokens == 0:\n","        return res\n","    else:\n","        return res / known_tokens"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"u5Q_4j7r6j1u"},"source":["Теперь у нас есть метод для создания векторного представления любого предложения."]},{"cell_type":"markdown","metadata":{"id":"EsJSNkhm6j1y"},"source":["#### Вопрос 2:\n","* Какая третья(с индексом 2) компонента вектора предложения `I love neural networks` (округлите до 2 знаков после запятой)?"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a62r11cT6j10","scrolled":true,"executionInfo":{"elapsed":43458,"status":"ok","timestamp":1614270654864,"user":{"displayName":"George Batchkala","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjDONxhSnrmdSTlEhvc2cJI7El4zBMhqZjcA1cl1A=s64","userId":"05060257197849650568"},"user_tz":0},"outputId":"0f06cf02-f505-4753-88d3-f174233683df"},"source":["sample_text = 'I love neural networks'\n","\n","print('With custom tokenizer:', question_to_vec(question=sample_text, embeddings=wv_embeddings, tokenizer=my_tokenizer)[2].round(2))\n","print('With nltk tokenizer:', question_to_vec(question=sample_text, embeddings=wv_embeddings, tokenizer=nltk_tokenizer)[2].round(2))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["With custom tokenizer: -1.29\n","With nltk tokenizer: -1.29\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"BGDLtfMKLIMW"},"source":["Ответ: -1.29\n","\n","Ответ одинаковый потому что в этом предлложении нет ни пунктуации, ни стоп-слов, поэтому tokenizer-ы работают одинаково."]},{"cell_type":"markdown","metadata":{"id":"Y60z4t6W6j16"},"source":["### Оценка близости текстов\n","\n","Представим, что мы используем идеальные векторные представления слов. Тогда косинусное расстояние между дублирующими предложениями должно быть меньше, чем между случайно взятыми предложениями. \n","\n","Сгенерируем для каждого из $N$ вопросов $R$ случайных отрицательных примеров и примешаем к ним также настоящие дубликаты. Для каждого вопроса будем ранжировать с помощью нашей модели $R + 1$ примеров и смотреть на позицию дубликата. Мы хотим, чтобы дубликат был первым в ранжированном списке.\n","\n","#### Hits@K\n","Первой простой метрикой будет количество корректных попаданий для какого-то $K$:\n","$$ \\text{Hits@K} = \\frac{1}{N}\\sum_{i=1}^N \\, [rank\\_q_i^{'} \\le K],$$\n","* $\\begin{equation*}\n","[x < 0 ] \\equiv \n"," \\begin{cases}\n","   1, &x < 0\\\\\n","   0, &x \\geq 0\n"," \\end{cases}\n","\\end{equation*}$ - индикаторная функция\n","* $q_i$ - $i$-ый вопрос\n","* $q_i^{'}$ - его дубликат\n","* $rank\\_q_i^{'}$ - позиция дубликата в ранжированном списке ближайших предложений для вопроса $q_i$.\n","\n","#### DCG@K\n","Второй метрикой будет упрощенная DCG метрика, учитывающая порядок элементов в списке путем домножения релевантности элемента на вес равный обратному логарифму номера позиции::\n","$$ \\text{DCG@K} = \\frac{1}{N} \\sum_{i=1}^N\\frac{1}{\\log_2(1+rank\\_q_i^{'})}\\cdot[rank\\_q_i^{'} \\le K],$$\n","С такой метрикой модель штрафуется за большой ранк корректного ответа"]},{"cell_type":"markdown","metadata":{"id":"8nZDyGctRX9u"},"source":["----\n","\n","**Мои комментарии:**\n","\n","1. Метрику Hits@K мы хотим приблизить как можно ближе к 1. Это достижимо когда для каждого $i$ выполняется $rank\\_q_i^{'} \\le K$. Тогда: $$\\text{Hits@K} = \\frac{1}{N}\\sum_{i=1}^N \\, [rank\\_q_i^{'} \\le K] = \\frac{1}{N}\\sum_{i=1}^N 1 = 1$$\n","\n","2. Идеально, если дупликат всегда на первом месте. Тогда $\\forall K \\ge 0$ выполняется Hits@K = 1\n","\n","3. Метрика DCG@K имеет тот же смымл: чем ближе к 1 (снизу) тем лучше. Но достичь идеального результата труднее. Теперь нам не достаточно выполнить $\\forall i : rank\\_q_i^{'} \\le K$, чтобы достичь  DCG@K=1. Теперь нужно $\\forall i : rank\\_q_i^{'} = 1$ потому что только в этом случае $$\\frac{1}{\\log_2(1+rank\\_q_i^{'})} = \\frac{1}{\\log_2(1+1)} = \\frac{1}{1} = 1$$. В противном случае, DCG@K < 1.\n","\n","4. Значения обеих метрик ограничены снизу 0. 0 достигается, если индикатор равен нулю для всех $i \\in \\{1,.., N\\}$\n","\n","----"]},{"cell_type":"markdown","metadata":{"id":"eHCnH-jw6j18"},"source":["#### Вопрос 3:\n","* Максимум `Hits@47 - DCG@1`?\n","\n","Ответ: 1\n","\n","Объясненние: Предположим, что для всех $i \\in \\{1,.., N\\}$ выполняется $rank\\_q_i^{'} = 2$. Тогда DCG@1 = 0, а Hits@47=1. Мы достигли максимальной возможной разницы, т.к. обе метрики оограничены интервалом [0, 1]."]},{"cell_type":"markdown","metadata":{"id":"_tFemBkP6j1-"},"source":["<img src='https://hsto.org/files/1c5/edf/dee/1c5edfdeebce4b71a86bdf986d9f88f2.jpg' width=400, height=200>"]},{"cell_type":"markdown","metadata":{"id":"0sUSxk866j1_"},"source":["#### Пример оценок\n","\n","Вычислим описанные выше метрики для игрушечного примера. \n","Пусть\n","* $N = 1$, $R = 3$\n","* <font color='green'>\"Что такое python?\"</font> - вопрос $q_1$\n","* <font color='red'>\"Что такое язык python?\"</font> - его дубликат $q_i^{'}$\n","\n","Пусть модель выдала следующий ранжированный список кандидатов:\n","\n","1. \"Как изучить с++?\"\n","2. <font color='red'>\"Что такое язык python?\"</font>\n","3. \"Хочу учить Java\"\n","4. \"Не понимаю Tensorflow\"\n","\n","$\\Rightarrow rank\\_q_i^{'} = 2$\n","\n","Вычислим метрику *Hits@K* для *K = 1, 4*:\n","\n","- [K = 1] $\\text{Hits@1} =  [rank\\_q_i^{'} \\le 1)] = 0$\n","- [K = 4] $\\text{Hits@4} =  [rank\\_q_i^{'} \\le 4] = 1$\n","\n","Вычислим метрику *DCG@K* для *K = 1, 4*:\n","- [K = 1] $\\text{DCG@1} = \\frac{1}{\\log_2(1+2)}\\cdot[2 \\le 1] = 0$\n","- [K = 4] $\\text{DCG@4} = \\frac{1}{\\log_2(1+2)}\\cdot[2 \\le 4] = \\frac{1}{\\log_2{3}}$"]},{"cell_type":"markdown","metadata":{"id":"B4L6HJJC6j2B"},"source":["#### Вопрос 4:\n","* Вычислите `DCG@10`, если $rank\\_q_i^{'} = 9$(округлите до одного знака после запятой)\n","\n","* [K = 10] $\\text{DCG@10} = \\frac{1}{\\log_2(1+9)}\\cdot[9 \\le 10] = \\frac{1}{\\log_2{10}} \\sim 3.3$"]},{"cell_type":"markdown","metadata":{"id":"J5xWOORI6j2F"},"source":["### HITS\\_COUNT и DCG\\_SCORE"]},{"cell_type":"markdown","metadata":{"id":"I1q9WQOx6j2H"},"source":["Каждая функция имеет два аргумента: $dup\\_ranks$ и $k$. $dup\\_ranks$ является списком, который содержит рейтинги дубликатов(их позиции в ранжированном списке). Например, $dup\\_ranks = [2]$ для примера, описанного выше."]},{"cell_type":"code","metadata":{"id":"F5VwySUB6j2J"},"source":["def hits_count(dup_ranks, k):\n","    \"\"\"\n","        dup_ranks: list индексов дубликатов\n","        result: вернуть  Hits@k\n","    \"\"\"\n","\n","    # inner brackets: compute all indicators\n","    hits_value = np.mean(np.array(dup_ranks) <= k)\n","    return hits_value    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p7d49iG1Y-Gw","executionInfo":{"elapsed":42549,"status":"ok","timestamp":1614270654864,"user":{"displayName":"George Batchkala","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjDONxhSnrmdSTlEhvc2cJI7El4zBMhqZjcA1cl1A=s64","userId":"05060257197849650568"},"user_tz":0},"outputId":"f92e9b96-3961-4c59-82ae-53f1ca576151"},"source":["# check if it works\n","nums = (np.array([1, 2, 3, 4, 5]) <= 3).astype(np.int)\n","denoms = 1 / np.log2(1 + np.array([1, 2, 3, 4, 5]))\n","\n","np.mean(nums * denoms)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.42618595071429155"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"id":"82hQaxCH6j2R"},"source":["def dcg_score(dup_ranks, k):\n","    \"\"\"\n","        dup_ranks: list индексов дубликатов\n","        result: вернуть DCG@k\n","    \"\"\"\n","    '''your code'''\n","    dup_ranks_arr = np.array(dup_ranks)\n","\n","    hit_indicators = (dup_ranks_arr <= k).astype(np.int)\n","    denoms = 1 / np.log2(1 + dup_ranks_arr)\n","\n","    dcg_value = np.mean(denoms * hit_indicators)\n","\n","    return dcg_value"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PcwHeXN26j2Y"},"source":["Протестируем функции. Пусть $N = 1$, то есть один эксперимент. Будем искать копию вопроса и оценивать метрики."]},{"cell_type":"code","metadata":{"id":"fjISmOEW6j2h"},"source":["import pandas as pd"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gLa_Wqfh6j2m","executionInfo":{"elapsed":42200,"status":"ok","timestamp":1614270654865,"user":{"displayName":"George Batchkala","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjDONxhSnrmdSTlEhvc2cJI7El4zBMhqZjcA1cl1A=s64","userId":"05060257197849650568"},"user_tz":0},"outputId":"9f4f8d76-d22b-4bcf-ac80-dd851a020f75"},"source":["copy_answers = [\"How does the catch keyword determine the type of exception that was thrown\",]\n","\n","# наги кандидаты\n","candidates_ranking = [[\"How Can I Make These Links Rotate in PHP\",\n","                       \"How does the catch keyword determine the type of exception that was thrown\",\n","                       \"NSLog array description not memory address\",\n","                       \"PECL_HTTP not recognised php ubuntu\"],]\n","# dup_ranks — позиции наших копий, так как эксперимент один, то этот массив длины 1\n","dup_ranks = [2] # Carefull! Best rank is 1, not 0.\n","\n","# вычисляем метрику для разных k\n","print('Ваш ответ HIT:', [hits_count(dup_ranks, k) for k in range(1, 5)])\n","print('Ваш ответ DCG:', [round(dcg_score(dup_ranks, k), 5) for k in range(1, 5)])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Ваш ответ HIT: [0.0, 1.0, 1.0, 1.0]\n","Ваш ответ DCG: [0.0, 0.63093, 0.63093, 0.63093]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"MoHC3YoQ6j2t"},"source":["У вас должно получиться"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":111},"id":"B0NFWq4f6j2u","scrolled":true,"executionInfo":{"elapsed":42051,"status":"ok","timestamp":1614270654874,"user":{"displayName":"George Batchkala","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjDONxhSnrmdSTlEhvc2cJI7El4zBMhqZjcA1cl1A=s64","userId":"05060257197849650568"},"user_tz":0},"outputId":"dd6f5f78-131b-4ecf-b151-1b33b13f7691"},"source":["# correct_answers - метрика для разных k\n","correct_answers = pd.DataFrame([[0, 1, 1, 1], [0, 1 / (np.log2(3)), 1 / (np.log2(3)), 1 / (np.log2(3))]],\n","                               index=['HITS', 'DCG'], columns=range(1,5))\n","correct_answers"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>HITS</th>\n","      <td>0</td>\n","      <td>1.00000</td>\n","      <td>1.00000</td>\n","      <td>1.00000</td>\n","    </tr>\n","    <tr>\n","      <th>DCG</th>\n","      <td>0</td>\n","      <td>0.63093</td>\n","      <td>0.63093</td>\n","      <td>0.63093</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      1        2        3        4\n","HITS  0  1.00000  1.00000  1.00000\n","DCG   0  0.63093  0.63093  0.63093"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"markdown","metadata":{"id":"tHZqgDTo6j0i"},"source":["### Данные\n","[Download link](https://drive.google.com/file/d/1QqT4D0EoqJTy7v9VrNCYD-m964XZFR7_/edit) for a zip file.\n","\n","You can just add a shortcut to your drive, or use the following command. In this case, there will be no need to mount the drive.\n","\n","`!gdown --id '1QqT4D0EoqJTy7v9VrNCYD-m964XZFR7_'`\n","\n","----\n","\n","`train.tsv` - выборка для обучения.<br> В каждой строке через табуляцию записаны: **<вопрос>, <похожий вопрос>**\n","\n","`validation.tsv` - тестовая выборка.<br> В каждой строке через табуляцию записаны: **<вопрос>, <похожий вопрос>, <отрицательный пример 1>, <отрицательный пример 2>, ...**"]},{"cell_type":"code","metadata":{"id":"jKVK2lDGvrIe","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614360292061,"user_tz":0,"elapsed":3406,"user":{"displayName":"George Batchkala","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjDONxhSnrmdSTlEhvc2cJI7El4zBMhqZjcA1cl1A=s64","userId":"05060257197849650568"}},"outputId":"443f4a18-c749-475f-8f3f-976bc119d8ac"},"source":["# try the next cell first to\n","\n","# !unzip stackoverflow_similar_questions.zip #__MACOSX/\\*# -d ./data/\n","# %rm -r __MACOSX/\n","# %rm data/.DS_Store"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Downloading...\n","From: https://drive.google.com/uc?id=1QqT4D0EoqJTy7v9VrNCYD-m964XZFR7_\n","To: /content/stackoverflow_similar_questions.zip\n","131MB [00:01, 117MB/s]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MbgYg8cFHc8d","executionInfo":{"status":"ok","timestamp":1614360294808,"user_tz":0,"elapsed":454,"user":{"displayName":"George Batchkala","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjDONxhSnrmdSTlEhvc2cJI7El4zBMhqZjcA1cl1A=s64","userId":"05060257197849650568"}},"outputId":"af591ded-5f8d-41a0-f97c-429efa00d560"},"source":["%ls"],"execution_count":3,"outputs":[{"output_type":"stream","text":["\u001b[0m\u001b[01;34msample_data\u001b[0m/  stackoverflow_similar_questions.zip\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"hil2UsUG6j22"},"source":["Считайте данные."]},{"cell_type":"code","metadata":{"id":"B4EBho8s6j26"},"source":["def read_corpus(filename):\n","    data = []\n","    for line in open(filename, encoding='utf-8'):\n","        q_data = line.split('\\t')\n","        data.append(q_data)\n","\n","    return data"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kkTxY3Mk9_nG"},"source":["Нам понадобиться только файл validation."]},{"cell_type":"code","metadata":{"id":"PTVB9Tnp6j29"},"source":["validation_data = read_corpus('./data/validation.tsv')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bTHfL-9y6j3F"},"source":["Кол-во строк"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z6ubXhIe6j3H","scrolled":false,"executionInfo":{"elapsed":45433,"status":"ok","timestamp":1614270659004,"user":{"displayName":"George Batchkala","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjDONxhSnrmdSTlEhvc2cJI7El4zBMhqZjcA1cl1A=s64","userId":"05060257197849650568"},"user_tz":0},"outputId":"4307e848-cfbe-4dd1-f3d8-2a26f0d0521b"},"source":["len(validation_data)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["3760"]},"metadata":{"tags":[]},"execution_count":28}]},{"cell_type":"markdown","metadata":{"id":"kaOQblBy6j3M"},"source":["Размер нескольких первых строк"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yRx6e-Pe6j3M","executionInfo":{"elapsed":45263,"status":"ok","timestamp":1614270659004,"user":{"displayName":"George Batchkala","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjDONxhSnrmdSTlEhvc2cJI7El4zBMhqZjcA1cl1A=s64","userId":"05060257197849650568"},"user_tz":0},"outputId":"3251f2cc-67bc-4724-91a8-3477a3a404bc"},"source":["for i in range(5):\n","    print(i + 1, len(validation_data[i]))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1 1001\n","2 1001\n","3 1001\n","4 1001\n","5 1001\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ySQQp0oQt1Ep"},"source":["### Ранжирование без обучения"]},{"cell_type":"markdown","metadata":{"id":"iElEDhj-6j3R"},"source":["Реализуйте функцию ранжирования кандидатов на основе косинусного расстояния. Функция должна по списку кандидатов вернуть отсортированный список пар (позиция в исходном списке кандидатов, кандидат). При этом позиция кандидата в полученном списке является его рейтингом (первый - лучший). Например, если исходный список кандидатов был [a, b, c], и самый похожий на исходный вопрос среди них - c, затем a, и в конце b, то функция должна вернуть список **[(2, c), (0, a), (1, b)]**."]},{"cell_type":"code","metadata":{"id":"NyX61VqEvvjX"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EVPRY3SxzYN4","executionInfo":{"elapsed":44940,"status":"ok","timestamp":1614270659005,"user":{"displayName":"George Batchkala","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjDONxhSnrmdSTlEhvc2cJI7El4zBMhqZjcA1cl1A=s64","userId":"05060257197849650568"},"user_tz":0},"outputId":"75522bf9-c7bb-482c-cea8-8f6e51e88c35"},"source":["# question and its vector representation\n","q = 'a'\n","qv = [0, 1]\n","\n","# candidates and their vector representations\n","cs = ['a', 'b', 'c', 'd']\n","cvs = [[0, 1], [1, 0], [0.2, 0.3], [0.5, 0.5]]\n","\n","trio = list(zip(range(len(cs)), cs, cvs))\n","trio"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(0, 'a', [0, 1]),\n"," (1, 'b', [1, 0]),\n"," (2, 'c', [0.2, 0.3]),\n"," (3, 'd', [0.5, 0.5])]"]},"metadata":{"tags":[]},"execution_count":30}]},{"cell_type":"code","metadata":{"id":"K02JARKr6j3T"},"source":["from sklearn.metrics.pairwise import cosine_similarity\n","from copy import deepcopy"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XPzZAND_CPmI","executionInfo":{"elapsed":44762,"status":"ok","timestamp":1614270659005,"user":{"displayName":"George Batchkala","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjDONxhSnrmdSTlEhvc2cJI7El4zBMhqZjcA1cl1A=s64","userId":"05060257197849650568"},"user_tz":0},"outputId":"dd69241e-0e48-4548-8e00-c6e3fb1fa4b3"},"source":["help(cosine_similarity)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Help on function cosine_similarity in module sklearn.metrics.pairwise:\n","\n","cosine_similarity(X, Y=None, dense_output=True)\n","    Compute cosine similarity between samples in X and Y.\n","    \n","    Cosine similarity, or the cosine kernel, computes similarity as the\n","    normalized dot product of X and Y:\n","    \n","        K(X, Y) = <X, Y> / (||X||*||Y||)\n","    \n","    On L2-normalized data, this function is equivalent to linear_kernel.\n","    \n","    Read more in the :ref:`User Guide <cosine_similarity>`.\n","    \n","    Parameters\n","    ----------\n","    X : ndarray or sparse array, shape: (n_samples_X, n_features)\n","        Input data.\n","    \n","    Y : ndarray or sparse array, shape: (n_samples_Y, n_features)\n","        Input data. If ``None``, the output will be the pairwise\n","        similarities between all samples in ``X``.\n","    \n","    dense_output : boolean (optional), default True\n","        Whether to return dense output even when the input is sparse. If\n","        ``False``, the output is sparse if both input arrays are sparse.\n","    \n","        .. versionadded:: 0.17\n","           parameter ``dense_output`` for dense output.\n","    \n","    Returns\n","    -------\n","    kernel matrix : array\n","        An array with shape (n_samples_X, n_samples_Y).\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"1nU6PvZCgch8"},"source":["#### Ranking: inefficient in memory and time (individually computing cosine similarity)."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ty-opCBnCfjk","executionInfo":{"elapsed":44607,"status":"ok","timestamp":1614270659005,"user":{"displayName":"George Batchkala","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjDONxhSnrmdSTlEhvc2cJI7El4zBMhqZjcA1cl1A=s64","userId":"05060257197849650568"},"user_tz":0},"outputId":"6ea95389-c4a1-46db-e288-7b0d747cd4b5"},"source":["# need to take [0][0]\n","cosine_similarity([[0, 1]], [[0, 1]])[0][0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1.0"]},"metadata":{"tags":[]},"execution_count":33}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pAU4yme_Boz2","executionInfo":{"elapsed":44525,"status":"ok","timestamp":1614270659006,"user":{"displayName":"George Batchkala","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjDONxhSnrmdSTlEhvc2cJI7El4zBMhqZjcA1cl1A=s64","userId":"05060257197849650568"},"user_tz":0},"outputId":"028dc784-91f6-403f-ca0e-5d28ec355b9a"},"source":["trio.sort(key=lambda t: cosine_similarity([t[2]], [qv])[0][0], reverse=True)\n","trio"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(0, 'a', [0, 1]),\n"," (2, 'c', [0.2, 0.3]),\n"," (3, 'd', [0.5, 0.5]),\n"," (1, 'b', [1, 0])]"]},"metadata":{"tags":[]},"execution_count":34}]},{"cell_type":"code","metadata":{"id":"1yP8wJWj6j3X"},"source":["def rank_candidates_basic(question, candidates, embeddings, tokenizer, dim=200):\n","    \"\"\"\n","        question: строка\n","        candidates: массив строк(кандидатов) [a, b, c]\n","        result: пары (начальная позиция, кандидат) [(2, c), (0, a), (1, b)]\n","    \"\"\"\n","    qv = question_to_vec(question=question, embeddings=embeddings, tokenizer=tokenizer)\n","\n","    # record candidate representations, takes memory and space here\n","    candidates_v = [question_to_vec(c, embeddings, tokenizer) for c in candidates]\n","\n","    # add the representations to the zipped unumerated candidates list\n","    # takes more space here, than if we just have enumerated list w/o representations\n","    trios = list(zip(range(len(candidates)), candidates, candidates_v))\n","\n","    # sort by the cosine similarity\n","    trios.sort(key=lambda t: cosine_similarity([t[2]], [qv])[0][0], reverse=True)\n","\n","    # drop the representations and return\n","    return [(t[0], t[1]) for t in trios]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MEuTdXtvhFRp"},"source":["#### Ranking: inefficient in time (individually computing cosine similarity), but less space used.\n","\n","We do not need to pre-compute and store the representation of each candidate. Instead - compute them straight away for sorting."]},{"cell_type":"code","metadata":{"id":"pzg7mcB9NLit"},"source":["def rank_candidates_slow(question, candidates, embeddings, tokenizer, dim=200):\n","    \"\"\"\n","        question: строка\n","        candidates: массив строк(кандидатов) [a, b, c]\n","        result: пары (начальная позиция, кандидат) [(2, c), (0, a), (1, b)]\n","    \"\"\"\n","\n","    # initial question representation\n","    # will reuse many times, so precompute\n","    qv = question_to_vec(question=question, embeddings=embeddings, tokenizer=tokenizer)\n","\n","    # enumerated candidates\n","    enum_candidates = list(zip(range(len(candidates)), candidates))\n","\n","    # sort by the cosine similarity between the representations of the\n","    # initial question and the representations of the candidate questions \n","    # computed on the fly\n","    enum_candidates.sort(key=lambda x: cosine_similarity(\n","                                            [question_to_vec(x[1], embeddings, tokenizer)],\n","                                            [qv]\n","                                            )[0][0],\n","                        reverse=True) # want decreasing order of cosine similarity\n","\n","    return [(ec[0], ec[1]) for ec in enum_candidates]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ECxv64MYhPsO"},"source":["#### Ranking: better in time (compute cosine similarity for all of the candidates in a vectorised form), but worse in space\n","\n","The 2 previous methods take 4-5 minutes for 1000 examples, this one takes ~1 minute"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CsRARCg0iM8U","executionInfo":{"elapsed":44101,"status":"ok","timestamp":1614270659006,"user":{"displayName":"George Batchkala","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjDONxhSnrmdSTlEhvc2cJI7El4zBMhqZjcA1cl1A=s64","userId":"05060257197849650568"},"user_tz":0},"outputId":"25f490d4-3568-495d-f7d1-eee2cfa03154"},"source":["# question and its vector representation\n","q = 'a'\n","qv = [0, 1]\n","\n","# candidates and their vector representations\n","cs = ['a', 'b', 'c', 'd']\n","cvs = [[0, 1], [1, 0], [0.2, 0.3], [0.5, 0.5]]\n","\n","print(np.array(qv).shape, np.array(cvs).shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(2,) (4, 2)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ErIf6_0FliN6","executionInfo":{"elapsed":44009,"status":"ok","timestamp":1614270659006,"user":{"displayName":"George Batchkala","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjDONxhSnrmdSTlEhvc2cJI7El4zBMhqZjcA1cl1A=s64","userId":"05060257197849650568"},"user_tz":0},"outputId":"72c59f80-4b89-4af1-fa06-f538237652ec"},"source":["dists = cosine_similarity([qv], cvs)\n","print(dists.shape, dists[0].shape)\n","\n","trio = list(zip(range(len(cs)), cs, dists[0]))\n","trio.sort(key=lambda x: x[2], reverse=True)\n","trio"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(1, 4) (4,)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[(0, 'a', 1.0),\n"," (2, 'c', 0.8320502943378436),\n"," (3, 'd', 0.7071067811865475),\n"," (1, 'b', 0.0)]"]},"metadata":{"tags":[]},"execution_count":38}]},{"cell_type":"code","metadata":{"id":"s2gpcqzCf7eG"},"source":["def rank_candidates(question, candidates, embeddings, tokenizer, dim=200):\n","    \"\"\"\n","        question: строка\n","        candidates: массив строк(кандидатов) [a, b, c]\n","        result: пары (начальная позиция, кандидат) [(2, c), (0, a), (1, b)]\n","    \"\"\"\n","\n","    # question vector\n","    question_v = question_to_vec(question=question, embeddings=embeddings, tokenizer=tokenizer)\n","    # record candidate representations, takes memory and space here\n","    candidate_vs = [question_to_vec(c, embeddings, tokenizer) for c in candidates]\n","\n","    # precomputing all together is faster (vectorized numpy operations)\n","    # (1, len(candidate_vs)), (len(candidate_vs),) -> (len(candidate_vs),)\n","    candidate_dists = cosine_similarity([question_v], candidate_vs)[0]\n","\n","    # enumerated candidates\n","    enum_candidates = list(zip(range(len(candidates)),\n","                               candidates,\n","                               candidate_dists)\n","    )\n","\n","    # sort by the cosine similarity between the representations of the\n","    # initial question and the representations of the candidate questions\n","    enum_candidates.sort(key=lambda x: x[2],\n","                         reverse=True) # want decreasing order of cosine similarity\n","\n","    return [(ec[0], ec[1]) for ec in enum_candidates]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TnBszTb76j3c"},"source":["Протестируйте работу функции на примерах ниже. Пусть $N=2$, то есть два эксперимента"]},{"cell_type":"code","metadata":{"id":"xvQgtP176j3h"},"source":["questions = ['converting string to list', 'Sending array via Ajax fails'] \n","\n","candidates = [['Convert Google results object (pure js) to Python object', # первый эксперимент\n","               'C# create cookie from string and send it',\n","               'How to use jQuery AJAX for an outside domain?'],\n","              \n","              ['Getting all list items of an unordered list in PHP',      # второй эксперимент\n","               'WPF- How to update the changes in list item of a list',\n","               'select2 not displaying search results']]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bPj1JGFi6j3m","executionInfo":{"elapsed":43676,"status":"ok","timestamp":1614270659007,"user":{"displayName":"George Batchkala","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjDONxhSnrmdSTlEhvc2cJI7El4zBMhqZjcA1cl1A=s64","userId":"05060257197849650568"},"user_tz":0},"outputId":"bc8d3e87-79af-482e-efa7-f08fe67b3108"},"source":["for question, q_candidates in zip(questions, candidates):\n","        print('Question:', question)\n","\n","        ranks = rank_candidates(question=question, candidates=q_candidates,\n","                                embeddings=wv_embeddings, tokenizer=my_tokenizer)\n","        for rank in ranks:\n","            print(rank)\n","        print()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Question: converting string to list\n","(1, 'C# create cookie from string and send it')\n","(0, 'Convert Google results object (pure js) to Python object')\n","(2, 'How to use jQuery AJAX for an outside domain?')\n","\n","Question: Sending array via Ajax fails\n","(0, 'Getting all list items of an unordered list in PHP')\n","(2, 'select2 not displaying search results')\n","(1, 'WPF- How to update the changes in list item of a list')\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"jm4cidj56j3q"},"source":["Для первого экперимента вы можете полностью сравнить ваши ответы и правильные ответы. Но для второго эксперимента два ответа на кандидаты будут <b>скрыты</b>(*)"]},{"cell_type":"code","metadata":{"id":"0LeKMIsn6j3s"},"source":["# должно вывести\n","results = [[(1, 'C# create cookie from string and send it'),\n","            (0, 'Convert Google results object (pure js) to Python object'),\n","            (2, 'How to use jQuery AJAX for an outside domain?')],\n","           [('*', 'Getting all list items of an unordered list in PHP'),        #скрыт\n","            ('*', 'select2 not displaying search results'),                     #скрыт\n","            ('*', 'WPF- How to update the changes in list item of a list')]]    #скрыт"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"t1ttnIBe6j3x"},"source":["Последовательность начальных индексов вы должны получить `для эксперимента 1`  1, 0, 2."]},{"cell_type":"markdown","metadata":{"id":"5WQgYDWd6j3y"},"source":["#### Вопрос 5:\n","* Какую последовательность начальных индексов вы получили `для эксперимента 2`(перечисление без запятой и пробелов, например, `102` для первого эксперимента?\n","\n","* Ответ: `021` если оспользовать .lower() в tokeniser-е, и `102` если использовать tokenizer из оригинальной версии этого jupyter notebook."]},{"cell_type":"markdown","metadata":{"id":"fPllOY-Y6j30"},"source":["Теперь мы можем оценить качество нашего метода. Запустите следующие два блока кода для получения результата. Обратите внимание, что вычисление расстояния между векторами занимает некоторое время (примерно 10 минут). Можете взять для validation 1000 примеров."]},{"cell_type":"code","metadata":{"id":"Z3q9sxddz-yU"},"source":["from tqdm.notebook import tqdm"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":83,"referenced_widgets":["9851defd92314769aad608d6af90f5cf","7012f0d3a4c3423c99818628a392e374","2444be56eec946cd855f4576a9264af5","1655a6c1272645f7b94504971249a8f8","560816be734345a79eb5b5c33ab799d3","0a9adfbe630f4b24a6c92eb2dbbedf2e","5761c518aae04e46b31903d49e9d773b","4a750dee054345a6a46b965187ecc8da"]},"id":"nu7K4mis6j32","executionInfo":{"elapsed":124726,"status":"ok","timestamp":1614270740623,"user":{"displayName":"George Batchkala","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjDONxhSnrmdSTlEhvc2cJI7El4zBMhqZjcA1cl1A=s64","userId":"05060257197849650568"},"user_tz":0},"outputId":"387a68eb-0c3c-46a6-e778-2a15dee93167"},"source":["wv_ranking = []\n","max_validation_examples = 1000\n","for i, line in enumerate(tqdm(validation_data)):\n","    if i == max_validation_examples:\n","        break\n","    q, *ex = line\n","    ranks = rank_candidates(q, ex, wv_embeddings, my_tokenizer)\n","    #print(q)\n","    #print(ranks)\n","\n","    \n","    # incorrect, indexes are not recorded as strings\n","    # wv_ranking.append([r[0] for r in ranks].index('0') + 1)\n","\n","    # Clear, but less efficient solution (writinfg in memory)\n","    #\n","    # all_ranks = [r[0] for r in ranks])\n","    # duplicate_index = all_ranks.index(0)   # duplicate is on the 0th position\n","    # duplicate_ rank = duplicate_index + 1  # ranks start from 1, unlike indexes\n","    # wv_ranking.append(duplicate_rank)\n","    #\n","    # the same, but all in one line\n","    wv_ranking.append([r[0] for r in ranks].index(0) + 1)\n","\n","print('Done!')\n","wv_ranking[::50]"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9851defd92314769aad608d6af90f5cf","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=3760.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Done!\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[5, 10, 124, 1, 1, 1, 664, 1, 1, 47, 1, 1, 66, 44, 16, 1, 5, 1, 1, 20]"]},"metadata":{"tags":[]},"execution_count":44}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":168,"referenced_widgets":["618445bfdbaf42df80fdf41f5da07987","9d26a4b8d7a94d2b9a463f27b0cf656b","5d5b691a31bd470780f4c1cace1d855a","86f525398c774ee6a870cf232b81bbff","b5272cdc883143c3a83eb48eb5d43af5","93208314c312407fa0a0e0492726b725","fa6ad6aea8ec48c1aa21863c56c9e6dd","b8a99cb7513b449ba972b3a0b3c46d67"]},"id":"GHb9aMFYOd5-","executionInfo":{"elapsed":124635,"status":"ok","timestamp":1614270740625,"user":{"displayName":"George Batchkala","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjDONxhSnrmdSTlEhvc2cJI7El4zBMhqZjcA1cl1A=s64","userId":"05060257197849650568"},"user_tz":0},"outputId":"d6ed2d5b-0af8-4d50-d109-4967db021f4a"},"source":["for k in tqdm([1, 5, 10, 100, 500, 1000]):\n","    print(\"DCG@%4d: %.3f | Hits@%4d: %.3f\" % (k, dcg_score(wv_ranking, k), k, hits_count(wv_ranking, k)))"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"618445bfdbaf42df80fdf41f5da07987","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=6.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["DCG@   1: 0.418 | Hits@   1: 0.418\n","DCG@   5: 0.505 | Hits@   5: 0.584\n","DCG@  10: 0.526 | Hits@  10: 0.652\n","DCG@ 100: 0.572 | Hits@ 100: 0.877\n","DCG@ 500: 0.585 | Hits@ 500: 0.974\n","DCG@1000: 0.588 | Hits@1000: 1.000\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"LL6_Rjg3InL8"},"source":["### Эмбеддинги, обученные на корпусе похожих вопросов"]},{"cell_type":"code","metadata":{"id":"iNvbpR5gJIPz"},"source":["train_data = read_corpus('./data/train.tsv')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Nr281ZyEJfjT"},"source":["Улучшите качество модели.<br>Склеим вопросы в пары и обучим на них модель Word2Vec из gensim. Выберите размер window. Объясните свой выбор."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f6Y46SSQMTL0","executionInfo":{"elapsed":127135,"status":"ok","timestamp":1614270743453,"user":{"displayName":"George Batchkala","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjDONxhSnrmdSTlEhvc2cJI7El4zBMhqZjcA1cl1A=s64","userId":"05060257197849650568"},"user_tz":0},"outputId":"d26fb142-2b14-4371-d8ab-9391b7de5709"},"source":["# original train data\n","print(\"n pairs:\", len(train_data), '\\n')\n","train_data[:3]"],"execution_count":null,"outputs":[{"output_type":"stream","text":["n pairs: 1000000 \n","\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[['converting string to list',\n","  'Convert Google results object (pure js) to Python object\\n'],\n"," ['Which HTML 5 Canvas Javascript to use for making an interactive drawing tool?',\n","  'Event handling for geometries in Three.js?\\n'],\n"," ['Sending array via Ajax fails',\n","  'Getting all list items of an unordered list in PHP\\n']]"]},"metadata":{"tags":[]},"execution_count":47}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9xc3xY6owL6J","executionInfo":{"elapsed":127053,"status":"ok","timestamp":1614270743454,"user":{"displayName":"George Batchkala","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjDONxhSnrmdSTlEhvc2cJI7El4zBMhqZjcA1cl1A=s64","userId":"05060257197849650568"},"user_tz":0},"outputId":"2cd7e879-a8bd-44eb-bd29-aea292664b0c"},"source":["# read about word2vec:\n","# https://radimrehurek.com/gensim/models/word2vec.html\n","\n","# glue the list of lists into the list of tuples (happens fast)\n","questions = [' '.join([l[0], l[1]]) for l in train_data]\n","questions[:3]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['converting string to list Convert Google results object (pure js) to Python object\\n',\n"," 'Which HTML 5 Canvas Javascript to use for making an interactive drawing tool? Event handling for geometries in Three.js?\\n',\n"," 'Sending array via Ajax fails Getting all list items of an unordered list in PHP\\n']"]},"metadata":{"tags":[]},"execution_count":48}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MwCGBHRx0DMR","executionInfo":{"elapsed":138559,"status":"ok","timestamp":1614270755055,"user":{"displayName":"George Batchkala","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjDONxhSnrmdSTlEhvc2cJI7El4zBMhqZjcA1cl1A=s64","userId":"05060257197849650568"},"user_tz":0},"outputId":"bf0cda33-6b8a-48c2-9d06-fa93d4383847"},"source":["proc_words = [my_tokenizer.tokenize(q) for q in questions]\n","for q in proc_words[:5]:\n","    print(q)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["['converting', 'string', 'list', 'convert', 'google', 'results', 'object', 'pure', 'js', 'python', 'object']\n","['html', '5', 'canvas', 'javascript', 'use', 'making', 'interactive', 'drawing', 'tool', 'event', 'handling', 'geometries', 'three', 'js']\n","['sending', 'array', 'via', 'ajax', 'fails', 'getting', 'list', 'items', 'unordered', 'list', 'php']\n","['insert', 'cookiecollection', 'cookiecontainer', 'c#', 'create', 'cookie', 'string', 'send']\n","['updating', 'one', 'element', 'bound', 'observable', 'collection', 'wpf', 'update', 'changes', 'list', 'item', 'list']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"3oP0b8TB19PN"},"source":["#### Choosing the window"]},{"cell_type":"code","metadata":{"id":"0Xi7bsNQ_nll"},"source":["# for all questions give the number of tokens\n","all_num_words = list(map(lambda q: len(my_tokenizer.tokenize(q)),\n","                    questions))\n","\n","quantiles_arr = np.quantile(all_num_words, [0, 0.25, 0.5, 0.75, 1])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":221},"id":"qclRw7rX2CBK","executionInfo":{"elapsed":146255,"status":"ok","timestamp":1614270762991,"user":{"displayName":"George Batchkala","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjDONxhSnrmdSTlEhvc2cJI7El4zBMhqZjcA1cl1A=s64","userId":"05060257197849650568"},"user_tz":0},"outputId":"f8614d7d-6056-4186-c8b8-589666555859"},"source":["print(\"Mean number of tokens per question:\",   np.mean(all_num_words))\n","\n","quantiles = {\n","    'quantile_names': ['min', 'lq', 'median', 'uq', 'max'],\n","    'quantiles': quantiles_arr\n","    \n","}\n","pd.DataFrame(quantiles)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mean number of tokens per question: 11.602786\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>quantile_names</th>\n","      <th>quantiles</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>min</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>lq</td>\n","      <td>9.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>median</td>\n","      <td>11.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>uq</td>\n","      <td>13.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>max</td>\n","      <td>61.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  quantile_names  quantiles\n","0            min        1.0\n","1             lq        9.0\n","2         median       11.0\n","3             uq       13.0\n","4            max       61.0"]},"metadata":{"tags":[]},"execution_count":51}]},{"cell_type":"markdown","metadata":{"id":"LvUx7GOS0uxc"},"source":["Есть примеры с большим количеством слов на вопрос. 11-12 слов в среднем и по медиане на склеенное предложение, поэтому window=11 будет охватывать все предложение даже для слов в начале каждого предложения."]},{"cell_type":"code","metadata":{"id":"HrHmMQnC4sDu"},"source":["from gensim.models import Word2Vec"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QuJzAM0cI-UH","executionInfo":{"elapsed":687181,"status":"ok","timestamp":1614271304165,"user":{"displayName":"George Batchkala","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjDONxhSnrmdSTlEhvc2cJI7El4zBMhqZjcA1cl1A=s64","userId":"05060257197849650568"},"user_tz":0},"outputId":"c232c581-9895-4d8f-9c1d-d8aee685e6e3"},"source":["%%time\n","embeddings_trained = Word2Vec(\n","                proc_words,     # data for model to train on [[token1, t2, ..., t11], [t1, t2, ..., t10], [], []]\n","                size=200,       # embedding vector size\n","                min_count=5,    # consider words that occured at least 5 times\n","                window=11,      # central word, `window` words to the left and `window` to the right\n","                sg=1,           # use skip-grams instead of CBOW\n","                workers=4).wv "],"execution_count":null,"outputs":[{"output_type":"stream","text":["CPU times: user 17min 26s, sys: 1.19 s, total: 17min 27s\n","Wall time: 9min\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1xKHviMDQsWw","executionInfo":{"elapsed":687102,"status":"ok","timestamp":1614271304167,"user":{"displayName":"George Batchkala","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjDONxhSnrmdSTlEhvc2cJI7El4zBMhqZjcA1cl1A=s64","userId":"05060257197849650568"},"user_tz":0},"outputId":"52826d0d-eb39-4540-cda8-6a3db323bf29"},"source":["embeddings_trained.index2word[:20]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['using',\n"," 'android',\n"," 'file',\n"," 'java',\n"," 'get',\n"," 'error',\n"," 'php',\n"," 'use',\n"," 'javascript',\n"," 'data',\n"," 'python',\n"," 'string',\n"," 'jquery',\n"," 'function',\n"," 'array',\n"," 'value',\n"," 'object',\n"," 'c#',\n"," 'net',\n"," 'class']"]},"metadata":{"tags":[]},"execution_count":54}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i3_DiY6Qwj-H","executionInfo":{"elapsed":687017,"status":"ok","timestamp":1614271304167,"user":{"displayName":"George Batchkala","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjDONxhSnrmdSTlEhvc2cJI7El4zBMhqZjcA1cl1A=s64","userId":"05060257197849650568"},"user_tz":0},"outputId":"0bcd7631-29a6-4057-b881-d838e37f983c"},"source":["embeddings_trained"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<gensim.models.keyedvectors.Word2VecKeyedVectors at 0x7fd5440d1410>"]},"metadata":{"tags":[]},"execution_count":55}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["f8d6d55d897d4570b291540b11468ef8","92dcbbb6ac59491191ce238ea767a270","c67e50b277124fc59519073d17c3e51a","59e94b410ba84b60a42fc9a36f8e6410","e2fe3448bab243be99074f86bf0f241c","f6383d73994e44478df1eacea5495ace","5b1ed1eb547b4122a1a09a759858a4d8","c4e01c9905c947e4bae347c4016bc8af"],"output_embedded_package_id":"1NLGHGB4Cys5apE_fCBZh2_wY_8i8S2Q2"},"id":"OQonbm4nMenD","executionInfo":{"elapsed":783336,"status":"ok","timestamp":1614271400567,"user":{"displayName":"George Batchkala","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjDONxhSnrmdSTlEhvc2cJI7El4zBMhqZjcA1cl1A=s64","userId":"05060257197849650568"},"user_tz":0},"outputId":"2ffc9332-90fc-4096-8984-e2d27fe0fb57"},"source":["wv_ranking = []\n","max_validation_examples = 1000\n","for i, line in enumerate(tqdm(validation_data)):\n","    if i == max_validation_examples:\n","        break\n","    q, *ex = line\n","    \n","    ranks = rank_candidates(q, ex, embeddings_trained, my_tokenizer)\n","    # ranks = rank_candidates(q, ex, wv_embeddings, my_tokenizer)\n","\n","    if i % 50 == 0:\n","        print(f\"Question {i}\")\n","        print(q)\n","        print(ex)\n","        print(ranks)\n","        print()\n","        \n","\n","    # wv_ranking.append([r[0] for r in ranks].index('0') + 1) # wrong, same as before\n","    wv_ranking.append([r[0] for r in ranks].index(0) + 1)\n","\n","wv_ranking[::50]"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LWwDmwj1Ca39","executionInfo":{"elapsed":783253,"status":"ok","timestamp":1614271400569,"user":{"displayName":"George Batchkala","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjDONxhSnrmdSTlEhvc2cJI7El4zBMhqZjcA1cl1A=s64","userId":"05060257197849650568"},"user_tz":0},"outputId":"d285e1f5-8614-4bc4-cc0e-650e59612cfc"},"source":["wv_ranking[::50]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[1, 2, 190, 1, 1, 1, 11, 1, 1, 1, 1, 1, 98, 20, 11, 1, 1, 1, 2, 20]"]},"metadata":{"tags":[]},"execution_count":57}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":168,"referenced_widgets":["a634d8905b61472d9a49ec98a8dd3c69","94edfbe393044f7d9a4a9eb2770098d1","35f7683d90d840978829ddde572e0aff","dc4c6a7200c44d608f6219eab4270e60","0f6756231d0d4eb7bf7956c8d48a098c","fe79bcadd97e40129488d13a2117ac16","526f58fe6d734e778d1c7b3128b11761","bc1ddf427a4d4b0ab1502911e5915085"]},"id":"3kahBUPGMgGR","executionInfo":{"elapsed":783170,"status":"ok","timestamp":1614271400577,"user":{"displayName":"George Batchkala","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjDONxhSnrmdSTlEhvc2cJI7El4zBMhqZjcA1cl1A=s64","userId":"05060257197849650568"},"user_tz":0},"outputId":"e5400e75-eeae-46f5-e269-a89b068e8605"},"source":["for k in tqdm([1, 5, 10, 100, 500, 1000]):\n","    print(\"DCG@%4d: %.3f | Hits@%4d: %.3f\" % (k, dcg_score(wv_ranking, k), k, hits_count(wv_ranking, k)))"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a634d8905b61472d9a49ec98a8dd3c69","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=6.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["DCG@   1: 0.534 | Hits@   1: 0.534\n","DCG@   5: 0.621 | Hits@   5: 0.696\n","DCG@  10: 0.640 | Hits@  10: 0.754\n","DCG@ 100: 0.675 | Hits@ 100: 0.922\n","DCG@ 500: 0.684 | Hits@ 500: 0.987\n","DCG@1000: 0.685 | Hits@1000: 1.000\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"tY8PxB0j-ThG"},"source":["### Замечание:\n","Решить эту задачу с помощью обучения полноценной нейронной сети будет вам предложено, как часть задания в одной из домашних работ по теме \"Диалоговые системы\"."]},{"cell_type":"markdown","metadata":{"id":"vymVj8IxO2PO"},"source":["Напишите свой вывод о полученных результатах.\n","* Какой принцип токенизации даёт качество лучше и почему?\n","* Помогает ли нормализация слов?\n","* Какие эмбеддинги лучше справляются с задачей и почему?\n","* Почему получилось плохое качество решения задачи?\n","* Предложите свой подход к решению задачи.\n","\n","## Вывод:\n"]},{"cell_type":"markdown","metadata":{"id":"emODHztAQUQz"},"source":["1. **Токенизация.** Новый кастомный tokeniser работает лучше, чем оригинальный, который делал `regex match` на `'w+'`. DGC@1 растет с 0.28 до 0.41 Происходит это по нескольким причинам:\n","    * Новый tokeniser использует `.lower()`. Поэтому Python и python будут иметь одно и то же представление.\n","    * Новый tokenizer также выбирает символы `[+#]*`, конкретно эти символы были выбраны, чтобы C++ и C# оставались сами собой. Скорее всего, есть и другие символы, которые тоже хорошо бы учесть, но ничего путного в голову не пришло.\n","    * Из-за того, как мы делаем embedding предложения (берем среднее векторов и не учитываем последовательность), использовать пунктуацию не имеет смысла.\n","    * Дополнительно, мы убираем английские стоп-слова из `nltk`.\n","\n","2. **Нормализация слов.** Лемматицация из spacy не помогла. Только замедлила процесс потому что пришлось делать следующее:\n","    * парсим с regex в лист и переводим в `.lower()` case.\n","    * соединяем через пробел, чтобы дать в spacy\n","    * берем `.lemma_` через list-comprehension и одновременно убираем стоп-слова\n","\n","3. **Embeddings.** Натренированный embedding справлялся примерно так же как предобученный, когда я использовал парамертры как из семинара (DGC@1 = 0.41). Я изменил алгоритм с CBOW на skip-grams, и качество натренированного эмбеддинга подскочило до (DGC@1 = HITS@1 = 0.53). Но теперь тренировка стала занимать 17 минут, так что решил перестать пробовать - слишком много времени на каждый эксперимент, а уже нужно вторую домашку начинать :)\n","\n","4. **Качество не блестящее**, но сносное (HITS@5 = 0.7). Улучшить скорее всего можно было бы с помощью более правильной комбинации regex для выбора нужных слов, может быть, что другая лемматизация дала бы качество лучше. В train set на самом деле не пары предложений, непонятно что делать, когда тройки и т.д. Зависит от того, похожие ли там вопросы или наоборот. Я решил брать только первые 2 вопроса. Это облегчает выбор window, так как количество tokens  равномернее в этом случае..\n","\n","5. **Как улучшить:** Можно взять предобученный embedding и дообучить его на нашем train set.\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"eGSsTF3gIB-S"},"source":["## Remove data folder, but leave the shortcut."]},{"cell_type":"code","metadata":{"id":"ZwyiBzcLIBD-"},"source":["%rm -r ./data"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L0BFRk8TIVpM","executionInfo":{"elapsed":783034,"status":"ok","timestamp":1614271400929,"user":{"displayName":"George Batchkala","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjDONxhSnrmdSTlEhvc2cJI7El4zBMhqZjcA1cl1A=s64","userId":"05060257197849650568"},"user_tz":0},"outputId":"48fad68b-9662-4fdd-efd0-3b48d606cda2"},"source":["%ls"],"execution_count":null,"outputs":[{"output_type":"stream","text":["'Copy of [homework]simple_embeddings.ipynb'\n","'SO_vectors_200.bin?download=1'\n"," stackoverflow_similar_questions.zip\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3DlDzqKrIX2S"},"source":[""],"execution_count":null,"outputs":[]}]}